# xAI
Explainability in modern AI architectures and LLMs

In this tutorial we will check some basic methodologies to ivestigate the inner workings of modern AI technique like LLMs and deep Neural networks like Transformers, CNN etc. 

We will provide code and also some analysis and taxonomy in xAI.

1. Explain the produced output based on the input
2. Explain the produced output based on the training data
3. Explain the role of individual neurons in embedding features
4. Extract explainable features from poly-semantic neurons