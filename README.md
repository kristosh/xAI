# xAI
Explainability in modern AI architectures and LLMs

In this tutorial we will check some basic methodologies to ivestigate the inner workings of modern AI technique like LLMs and deep Neural networks like Transformers, CNN etc. 

We will provide code and also some analysis and taxonomy in xAI.

Explain the produced output based on the input (features attributions)
Explain the produced output based on the training data
Explain the role of individual neurons in embedding features
Extract explainable features from poly-semantic neurons